{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import random as rn\n",
    "import time\n",
    "import math as m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class vocab_word:\n",
    "    #trace from the root\n",
    "    point=[]\n",
    "    #huffman code\n",
    "    code=[]\n",
    "    def __init__(self, word, count):\n",
    "        self.count = count\n",
    "        self.word = word\n",
    "     \n",
    "    #object print \n",
    "    def __repr__(self):\n",
    "        return repr(( self.word,self.count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "threshold = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "vocab = pickle.load( open( \"vocab.p\", \"rb\" ) )\n",
    "\n",
    "syn0=pickle.load( open( \"WeightMatrix.p\", \"rb\" ) )\n",
    "#CreateBinaryTree()\n",
    "\n",
    "#make it all uppercase \n",
    "for i in xrange(len(vocab)):\n",
    "    vocab[i].word=vocab[i].word.upper()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vocab[:]=vocab[:threshold]\n",
    "vocab_size=len(vocab)\n",
    "\n",
    "idx={}\n",
    "invidx={}\n",
    "for i in xrange(vocab_size):\n",
    "    if(vocab[i].word in idx):continue \n",
    "    idx[vocab[i].word]=i\n",
    "    \n",
    "#save word index and weight matrix\n",
    "for i in xrange(vocab_size):\n",
    "    invidx[i]=vocab[i].word\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print  top k  \n",
    "def print_topk(query,matrix,idx,inv_idx,k):\n",
    "    rank={}\n",
    "    topk=[]\n",
    "    query=query.upper()\n",
    "    for i in xrange(threshold):\n",
    "        if(i==idx[query]):continue \n",
    "        sim=np.dot(matrix[idx[query]],matrix[i])\n",
    "        rank[i]=sim\n",
    "    topk=sorted(rank.items(), key=lambda x: x[1],reverse=True)\n",
    "    \n",
    "    for i in xrange(k):\n",
    "        print (inv_idx[topk[i][0]],topk[i][1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def normalize(weight):\n",
    "    for i in xrange(threshold):\n",
    "        norm=0\n",
    "        for j in xrange(weight.shape[1]):\n",
    "            norm+=weight[i][j]**2\n",
    "        norm=m.sqrt(norm)\n",
    "        weight[i]=weight[i]/float(norm)\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "threshold=50000\n",
    "\n",
    "def normalize_accel(np.ndarray[np.float64_t, ndim=2] weight):\n",
    "    cdef float norm=0\n",
    "    for i in xrange(threshold):\n",
    "        norm=0\n",
    "        for j in xrange(weight.shape[1]):\n",
    "            norm+=weight[i][j]**2\n",
    "        norm=norm**(0.5)\n",
    "        weight[i]=weight[i]/float(norm)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def normalize_vec(vector): \n",
    "    norm=0\n",
    "    for j in xrange(len(vector)):\n",
    "        norm+=vector[j]**2\n",
    "    \n",
    "    norm=norm**0.5\n",
    "    vector=vector/float(norm)\n",
    "    return vector \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "\n",
    "def normalize_vec_accel(np.ndarray[np.float64_t, ndim=1] vector): \n",
    "    cdef float norm=0\n",
    "    for j in xrange(len(vector)):\n",
    "        norm+=vector[j]**2\n",
    "    \n",
    "    norm=norm**0.5\n",
    "    vector=vector/float(norm)\n",
    "    return vector \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.03 s, sys: 0 ns, total: 1.03 s\n",
      "Wall time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "normalize(syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 944 ms, sys: 52 ms, total: 996 ms\n",
      "Wall time: 920 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "normalize_accel(syn0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "norm=0\n",
    "for j in xrange(syn0.shape[1]):\n",
    "    norm+=syn0[1][j]**2\n",
    "print(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analogytask(vector,idx,inv_idx):\n",
    "    maxim=.0\n",
    "    maxword=''\n",
    "    accuracy=0\n",
    "    count=0\n",
    "    \n",
    "    for i in xrange(threshold):\n",
    "        sim=np.dot(vector,syn0[i])\n",
    "        if(maxim<sim):\n",
    "            maxim=sim\n",
    "            maxword=inv_idx[i]\n",
    "            \n",
    "    return maxword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analogytask_topk(vector,idx,inv_idx,k):\n",
    "    rank={}\n",
    "    topk=[]\n",
    "    for i in xrange(threshold):\n",
    "        sim=np.dot(vector,syn0[i])\n",
    "        rank[i]=sim\n",
    "    topk=sorted(rank.items(), key=lambda x: x[1],reverse=True)\n",
    "    \n",
    "    return [inv_idx[topk[i][0]] for i in xrange(k)]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 152 ms, sys: 0 ns, total: 152 ms\n",
      "Wall time: 151 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec=normalize_vec(syn0[idx['man'.upper()]]-syn0[idx['king'.upper()]]+syn0[idx['queen'.upper()]])\n",
    "vec2=syn0[idx['capital'.upper()]]+syn0[idx['japan'.upper()]]\n",
    "analogytask_topk(vec,idx,invidx,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MAN', 'WOMAN', 'DOG', 'GIRL']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogytask_topk(vec,idx,invidx,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 57.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec=normalize_vec(syn0[idx['korean'.upper()]]-syn0[idx['korea'.upper()]]+syn0[idx['japan'.upper()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 35 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec=normalize_vec_accel(syn0[idx['korean'.upper()]]-syn0[idx['korea'.upper()]]+syn0[idx['japan'.upper()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluation(matrix,idx,inv_idx):\n",
    "    with open('../data/questions-words.txt', 'rb') as train_file:\n",
    "        train_file.readline()\n",
    "        totalcount = 0\n",
    "        words=[]\n",
    "        result=[]\n",
    "        accur=0\n",
    "        for line in train_file:\n",
    "            words=line.split()\n",
    "            if(len(words)<3):\n",
    "                continue\n",
    "                \n",
    "            words[0]=words[0].upper()\n",
    "            words[1]=words[1].upper()\n",
    "            words[2]=words[2].upper()\n",
    "            words[3]=words[3].upper()\n",
    "            \n",
    "            not_include=words[:3]\n",
    "            \n",
    "            #same as the given word continue \n",
    "            if(words[0] not in idx or words[1] not in idx or words[2] not in idx or words[3] not in idx):\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            lin_cal=matrix[idx[words[1]]]-matrix[idx[words[0]]]+matrix[idx[words[2]]]\n",
    "            lin_cal=normalize_vec_accel(lin_cal)\n",
    "            result=analogytask_topk(lin_cal,idx,invidx,4)\n",
    "            \n",
    "            for i in xrange(len(result)):           \n",
    "                if(result[i] in not_include):\n",
    "                    continue \n",
    "                if(result[i]==words[3]):\n",
    "                    accur+=1\n",
    "                    break  \n",
    "                if(result[i] not in words):\n",
    "                    break        \n",
    "            totalcount+=1\n",
    "        print(totalcount)\n",
    "        print(accur)\n",
    "        print(accur/float(totalcount))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15790\n",
      "1001\n",
      "0.0633945535149\n",
      "CPU times: user 23min 18s, sys: 560 ms, total: 23min 19s\n",
      "Wall time: 23min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluation(syn0,idx,invidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('POP', 0.93122598661943123)\n",
      "('BLUES', 0.92697214812822215)\n",
      "('PUNK', 0.92615348364900951)\n",
      "('RAP', 0.92420971046826317)\n",
      "('HOP', 0.91652583386905406)\n",
      "('DISCO', 0.90802467965995015)\n",
      "('FOLK', 0.90742165525090535)\n",
      "('MUSIC', 0.89954854602555612)\n",
      "('MUSICIANS', 0.89745459325992571)\n",
      "('HIP', 0.89445943635573333)\n"
     ]
    }
   ],
   "source": [
    "print_topk('jazz',syn0,idx,invidx,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
